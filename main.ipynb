{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663253aa",
   "metadata": {},
   "source": [
    "# Model PyTorch → ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906e4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# ============================================================\n",
    "# 0. Pastikan onnx & onnxruntime terinstall\n",
    "# ============================================================\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"[INFO] {package} belum ada. Menginstall...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "for pkg in [\"onnx\", \"onnxruntime\"]:\n",
    "    install_if_missing(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a950ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Import library utama\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463852ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Definisi Model (sama seperti sebelumnya)\n",
    "# ============================================================\n",
    "def get_model(num_classes, variant=\"large\"):\n",
    "    if variant == \"large\":\n",
    "        model = models.mobilenet_v3_large(weights=\"IMAGENET1K_V1\")\n",
    "        in_feats = model.classifier[0].in_features\n",
    "    else:\n",
    "        model = models.mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "        in_feats = model.classifier[0].in_features\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_feats, 128),\n",
    "        nn.Hardswish(),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(128, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8b0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Fungsi export\n",
    "# ============================================================\n",
    "def export_to_onnx(pt_path, onnx_path, num_classes=2, variant=\"large\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model\n",
    "    model = get_model(num_classes=num_classes, variant=variant).to(device)\n",
    "    state_dict = torch.load(pt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # Dummy input (sesuai training)\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "    # Export\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        opset_version=13\n",
    "    )\n",
    "    print(f\"[INFO] Export sukses: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ea6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harry\\AppData\\Local\\Temp\\ipykernel_57916\\1428721856.py:17: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Export sukses: models/onnx/face-expression.onnx\n",
      "[INFO] Export sukses: models/onnx/pose-recognition.onnx\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. Eksekusi untuk dua model\n",
    "# ============================================================\n",
    "os.makedirs(\"models/onnx\", exist_ok=True)\n",
    "\n",
    "export_to_onnx(\"models/face-expression.pt\", \"models/onnx/face-expression.onnx\")\n",
    "export_to_onnx(\"models/pose-recognition.pt\", \"models/onnx/pose-recognition.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9933f3b5",
   "metadata": {},
   "source": [
    "# Model ONNX → HEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# ============================================================\n",
    "# 1. Fungsi compile ONNX -> HEF\n",
    "# ============================================================\n",
    "def compile_to_hef(onnx_path, hef_path, hw_arch=\"hailo8\"):\n",
    "    \"\"\"\n",
    "    Compile ONNX model to HEF using Hailo Model Compiler.\n",
    "    hw_arch bisa hailo8 / hailo10h / hailo10h-r depending on device.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cmd = [\n",
    "            \"hailo_model_compiler\",\n",
    "            \"--onnx\", onnx_path,\n",
    "            \"--hw-arch\", hw_arch,\n",
    "            \"--output\", hef_path\n",
    "        ]\n",
    "        print(f\"[INFO] Running: {' '.join(cmd)}\")\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"[INFO] HEF berhasil dibuat: {hef_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"[ERROR] Gagal compile {onnx_path} -> {hef_path}\")\n",
    "        print(e)\n",
    "\n",
    "# ============================================================\n",
    "# 2. Path ONNX dan Output HEF\n",
    "# ============================================================\n",
    "onnx_dir = \"models/onnx\"\n",
    "hef_dir = \"models/hef\"\n",
    "os.makedirs(hef_dir, exist_ok=True)\n",
    "\n",
    "models = {\n",
    "    \"face-expression\": os.path.join(onnx_dir, \"/face-expression.onnx\"),\n",
    "    \"pose-recognition\": os.path.join(onnx_dir, \"/pose-recognition.onnx\")\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# 3. Compile semua model\n",
    "# ============================================================\n",
    "for name, onnx_path in models.items():\n",
    "    hef_path = os.path.join(hef_dir, f\"{name}.hef\")\n",
    "    compile_to_hef(onnx_path, hef_path, hw_arch=\"hailo8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convert-model-to-hailo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
